---
title: "Introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  fig.align = "center",     
  fig.width = 6,            
  fig.height = 4            
)
```

This vignette demonstrates how to use functions from the `ssstats` package to carry out common statistical tasks in R. To follow along, load the required packages:

```{r}
library(ssstats)
library(palmerpenguins)
```

# Summary and Distribution of Continuous Variables

When working with continuous data, it is important to examine measures of central tendency (mean, median, mode), distribution, and the correlation between variables. We will use the penguins dataset from the `palmerpenguins` package.

```{r}
mean_median(penguins, bill_length_mm, bill_depth_mm, flipper_length_mm)
normality_correlation(penguins, method = "spearman")
```

The correlation matrix includes `NA` values due to missing data. To avoid this, and to exclude numerically coded categorical variables, clean the data before applying the `normality_correlation()` function:

```{r}
penguins_clean <- na.omit(penguins)
normality_correlation(penguins_clean, method = "spearman")
```

# Counts and Percentages for Categorical Variables

For categorical variables, use n_pct() to generate one-way or two-way frequency and percentage tables. For example, to examine the distribution of penguins by sex:

```{r}
n_pct(penguins_clean, sex)
```

You can also summarize by two variables. For instance, to see the distribution of species across years:

```{r}
n_pct(penguins_clean, row_var = year, col_var = species)
```

By default, percentages are column-based. You can also specify `type = "row"` or `type = "all"` to change the denominator.

# One-Sample Inference for Means and Proportions

Depending on our research goals, we might be interested in comparing an observed mean or proportion to a specified value to assess statistical significance. The `ssstats` package provides the `one_mean_*` and `one_prop_*` functions to perform hypothesis tests and compute confidence intervals for means and proportions, respectively.

For demonstration purposes, let us test whether the mean bill length is greater than 40 mm (assuming 40 mm is a relevant benchmark for penguin bill length):


```{r}
one_mean_HT(penguins_clean, continuous = bill_length_mm, mu = 40, alternative = "greater", alpha = 0.05)
```

As shown in the output, we obtain a very small p-value and reject the null hypothesis that $\mu = 40$ at the $\alpha = 0.05$ level. Since this is a one-sided test (alternative = "greater"), we conclude that there is sufficient evidence to suggest the true population mean bill length exceeds 40 mm.

To compute the corresponding confidence interval and point estimate:

```{r}
one_mean_CI(data = penguins_clean, continuous = bill_length_mm, confidence = 0.95)
```

We can conduct a similar analysis for proportions. For example, let us test the null hypothesis that 50% of the penguins in our research population are of the Adelie species:

```{r}
one_prop_HT(data = penguins_clean, binary = species, event = "Adelie", p = 0.5, alternative = "two.sided", alpha = 0.05)
```

To obtain the confidence interval for this proportion:

```{r}
one_prop_CI(data = penguins_clean, binary = species, event = "Adelie", confidence = 0.95)
```



# Comparing Groups: Independent Samples t-Test

Suppose we want to compare bill length between male and female penguins. First, check the assumption of within-group normality using QQ plots:

```{r}
independent_qq(penguins_clean, continuous = bill_length_mm, grouping = sex)
```

The QQ plots suggest deviations from normality, but with a large enough sample size, the Central Limit Theorem justifies using a t-test. Please note that this example is for illustration only. In practice, a non-parametric test may be more appropriate.

Now perform a two-sample t-test assuming equal variance:

```{r}
independent_mean_HT(
  penguins_clean,
  continuous = bill_length_mm,
  grouping = sex,
  alternative = "two.sided",
  alpha = 0.05,
  variance = "equal"
)
```

The result suggests a statistically significant difference in bill length between sexes. To estimate the magnitude of this difference, we compute a 95% confidence interval:

```{r}
independent_mean_CI(
  penguins_clean,
  grouping = "sex",
  continuous = "bill_length_mm",
  confidence = 0.95
)
```

With 95% confidence, females have bills that are, on average, 2.65 to 4.87 mm shorter than males, which is a more informative conclusion than simply noting a difference! 

# Comparing Groups: Beyond t-Test

In the previous example, we performed a two-sample t-test to see if there was a statistically significant different between male and female penguins with respect to bill length. However, we did not account for differences in bill length by species. We can resort to a regression model to determine if the same difference in bill length persists even after adjusting for species. 

```{r}
model <- lm(bill_length_mm ~ sex + species, data = penguins_clean)
```

Now, we use the `anova_check` function to assess the assumptions of a linear model. 

```{r}
anova_check(model)
```

There is no clear evidence of either heteroscedasticity or non-normality of residuals; however, there are some points with large residuals (~10). Let us further examine these points. 

In linear regression, outliers are points with large residuals, while influential points are those that significantly affect the model’s estimates. We examine residuals to assess model fit and Cook’s distance to identify observations that unduly influence the regression. 

We begin with outlier detection. While definitions vary, we define outliers as observations with standardized residuals greater than 2.5 or less than -2.5. The function returns a `ggplot` object, allowing for further customization using `+`. In this example, point shapes are varied by penguin species to aid interpretation.

```{r}
outlier_count(penguins_clean, model)
outlier_graph(df = penguins_clean, model = model, 
              x_var = bill_depth_mm, y_var = bill_length_mm) +
  ggplot2::aes(shape = species) +
  ggplot2::scale_shape_manual(values = c(16, 17, 15))
```

There is no indication of data entry errors (such as negative lengths) or other anomalies that would justify excluding these observations. Therefore, we retain them in the analytic sample and proceed to examine influential points. As with outliers, the definition of an influential observation varies. In this package, users can choose from three commonly used thresholds for identifying influential points based on Cook’s distance: (1) the \textit{matlab} rule, which flags values exceeding three times the mean Cook’s distance; (2) the \textit{baseR} convention, which highlights points with Cook’s distance greater than 0.5 or 1; and (3) the \textit{conventional} rule, which flags values above $4/n$, where $n$ is the sample size. The \textit{conventional} rule is used by default. 

```{r}
cooks(model, show.threshold = T, n_labels_desired = 3)
```

Observations 179, 283, and 296 appear to be influential. While alternative modeling approaches, such as robust regression, quantile regression, or generalized linear models with a gamma distribution, may be appropriate, we proceed under the assumption that retaining these points does not unduly compromise our analysis. We now turn to the regression coefficients to connect our findings with the earlier t-test results.

```{r}
summary(model)$coef
```

Even after adjusting for species, there is a significant difference in mean bill length between males and females. Specifically, holding species constant, males are expected to have bills that are 3.694 mm longer than females (95% CI: 3.193, 4.195). These results are consistent with the earlier t-test, though the estimated difference is slightly smaller.

# Dependent t-Test

The `penguins` dataset does not contain variables suitable for demonstrating dependent t-test procedures using `ssstats`. To that end, we will generate a synthetic dataset. Let us simulate standardized pre- and post-test scores for 500 individuals. This type of data is commonly referred to as "wide" format, where each row corresponds to an individual and each column to a measurement occasion. The dependent t-test functions in `ssstats` require data in this format. If your data is currently in "long" format (where each row is a single measurement), consider reshaping it using tools from packages such as `tidyr`

```{r}
set.seed(123)  

# Number of observations
n <- 100

# Mean and standard deviation for pre and post
mu_pre <- 0
mu_post <- 1
sd_pre <- 1
sd_post <- 1

# correlation between pre and post
rho <- 0.6 

# Define variance-covariance matrix for bivariate normal

Sigma <- matrix(c(sd_pre^2, rho * sd_pre * sd_post,
                  rho * sd_pre * sd_post, sd_post^2), 
                nrow = 2)

bivn <- MASS::mvrnorm(n = n, mu = c(mu_pre, mu_post), Sigma = Sigma)
pre <- bivn[, 1]
post <- bivn[, 2]
id <- 1:n

data <- data.frame(id = id, pre = pre, post = post)
```

Let us begin by examining the distribution of the difference between the post- and pre-test scores. Specifically, we will inspect the QQ plot of the differences to assess the normality assumption required for the paired t-test. We will also compute the mean and median of the difference for a quick descriptive summary.

```{r}
# Compare means and medians of pre and post scores
dependent_mean_median(data, col1 = pre, col2 = post, accuracy = 3)

# Examine QQ plot of the difference (post - pre)
dependent_qq(data, col1 = pre, col2 = post)
```

Assuming that all appropriate criteria for a t-test are met, we can proceed with the dependent t-test. 

```{r}
dependent_mean_HT(data = data, col1 = pre, col2 = post, alternative = "two.sided", alpha = 0.05, mu = 0)
```

We complete this example by examining the 95% confidence interval for this difference. 

```{r}
dependent_mean_CI(data = data, col1 = pre, col2 = post, confidence = 0.95)
```

